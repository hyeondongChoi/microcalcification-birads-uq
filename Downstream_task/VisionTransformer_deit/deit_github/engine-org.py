# Copyright (c) 2015-present, Facebook, Inc.
# All rights reserved.
"""
Train and eval functions used in main.py
"""
import math
import sys
from typing import Iterable, Optional

import torch

from timm.data import Mixup
from timm.utils import accuracy, ModelEma

from losses import DistillationLoss
import utils

import numpy as np
from sklearn.metrics import confusion_matrix, classification_report

from torch.utils.data import Dataset, DataLoader
import pandas as pd
import os
from PIL import Image
import torchvision.transforms as transforms
import ast
from collections import Counter

class InferenceDataset(Dataset):
    def __init__(self, csv_file, transform=None):
        self.data = pd.read_csv(csv_file)
        self.transform=transform

        self.label_map = {"grade 3": 0, "grade 4": 1}

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        row = self.data.iloc[idx]

        patient_id = row["patient_id"]
        laterality = row["laterality"]  # "Left" ë˜ëŠ” "Right"
        grade = row["grade"]
        image_paths = ast.literal_eval(row["files"])  # ë¬¸ìžì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜

        # ðŸ”¹ íŒ¨ì¹˜ ë²ˆí˜¸ë³„ë¡œ ì´ë¯¸ì§€ ê·¸ë£¹í™”
        patch_dict = {}
        for img_path in image_paths:
            filename = os.path.basename(img_path)
            patch_num = int(filename.split("_patch_")[1].split(".")[0])  # íŒ¨ì¹˜ ë²ˆí˜¸ ì¶”ì¶œ

            if patch_num not in patch_dict:
                patch_dict[patch_num] = []
            patch_dict[patch_num].append(img_path)

        # ðŸ”¹ íŒ¨ì¹˜ ë²ˆí˜¸ ìˆœì„œëŒ€ë¡œ 2D ë¦¬ìŠ¤íŠ¸ ìƒì„±
        grouped_images = []
        for patch_num in sorted(patch_dict.keys()):
            images = []
            for img_path in sorted(patch_dict[patch_num]):  # LCC & LMLO ìˆœì„œ ì •ë ¬
                image = Image.open(img_path).convert('RGB')  # RGB ë³€í™˜

                if self.transform:
                    image = self.transform(image)

                images.append(image)

            grouped_images.append(torch.stack(images))

        grouped_images = torch.stack(grouped_images)

        label = self.label_map[grade]

        return grouped_images, label

class InferenceDataset_Open(Dataset):
    def __init__(self, csv_file, transform=None):
        self.data = pd.read_csv(csv_file)
        self.transform = transform

        self.label_map = {"grade 3": 0, "grade 4": 1}

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        row = self.data.iloc[idx]

        patient_id = row["patient_id"]
        laterality = row["laterality"]  # "Left" ë˜ëŠ” "Right"
        grade = row["grade"]
        image_paths = ast.literal_eval(row["files"])  # ë¬¸ìžì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜

        # ðŸ”¹ íŒ¨ì¹˜ ë²ˆí˜¸ë³„ë¡œ ì´ë¯¸ì§€ ê·¸ë£¹í™” (íŒ¨ì¹˜ ì •ë³´ê°€ íŒŒì¼ ì´ë¦„ ëì— ìžˆìŒ)
        patch_dict = {}
        for img_path in image_paths:
            filename = os.path.basename(img_path)
            patch_num = int(filename.split("_")[-1].split(".")[0])  # íŒ¨ì¹˜ ë²ˆí˜¸ ì¶”ì¶œ

            if patch_num not in patch_dict:
                patch_dict[patch_num] = []
            patch_dict[patch_num].append(img_path)

        # ðŸ”¹ íŒ¨ì¹˜ ë²ˆí˜¸ ìˆœì„œëŒ€ë¡œ 2D ë¦¬ìŠ¤íŠ¸ ìƒì„±
        grouped_images = []
        for patch_num in sorted(patch_dict.keys()):
            images = []
            for img_path in sorted(patch_dict[patch_num]):  # CC & MLO ìˆœì„œ ì •ë ¬
                image = Image.open(img_path).convert('RGB')  # RGB ë³€í™˜

                if self.transform:
                    image = self.transform(image)

                images.append(image)

            grouped_images.append(torch.stack(images))

        grouped_images = torch.stack(grouped_images)

        label = self.label_map[grade]

        return grouped_images, label



def train_one_epoch(model: torch.nn.Module, criterion: DistillationLoss,
                    data_loader: Iterable, optimizer: torch.optim.Optimizer,
                    device: torch.device, epoch: int, loss_scaler, max_norm: float = 0,
                    model_ema: Optional[ModelEma] = None, mixup_fn: Optional[Mixup] = None,
                    set_training_mode=True, args = None):
    model.train(set_training_mode)
    metric_logger = utils.MetricLogger(delimiter="  ")
    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))
    header = 'Epoch: [{}]'.format(epoch)
    print_freq = 10
    
    if args.cosub:
        criterion = torch.nn.BCEWithLogitsLoss()

    for samples, targets in metric_logger.log_every(data_loader, print_freq, header):
        samples = samples.to(device, non_blocking=True)
        targets = targets.to(device, non_blocking=True)

        if mixup_fn is not None:
            samples, targets = mixup_fn(samples, targets)
            
        if args.cosub:
            samples = torch.cat((samples,samples),dim=0)
            
        if args.bce_loss:
            targets = targets.gt(0.0).type(targets.dtype)
         
        with torch.cuda.amp.autocast():
            outputs = model(samples)
            if not args.cosub:
                loss = criterion(samples, outputs, targets)
            else:
                outputs = torch.split(outputs, outputs.shape[0]//2, dim=0)
                loss = 0.25 * criterion(outputs[0], targets) 
                loss = loss + 0.25 * criterion(outputs[1], targets) 
                loss = loss + 0.25 * criterion(outputs[0], outputs[1].detach().sigmoid())
                loss = loss + 0.25 * criterion(outputs[1], outputs[0].detach().sigmoid())

        loss_value = loss.item()

        if not math.isfinite(loss_value):
            print("Loss is {}, stopping training".format(loss_value))
            sys.exit(1)

        optimizer.zero_grad()

        # this attribute is added by timm on one optimizer (adahessian)
        is_second_order = hasattr(optimizer, 'is_second_order') and optimizer.is_second_order
        loss_scaler(loss, optimizer, clip_grad=max_norm,
                    parameters=model.parameters(), create_graph=is_second_order)

        torch.cuda.synchronize()
        if model_ema is not None:
            model_ema.update(model)

        metric_logger.update(loss=loss_value)
        metric_logger.update(lr=optimizer.param_groups[0]["lr"])
    # gather the stats from all processes
    metric_logger.synchronize_between_processes()
    print("Averaged stats:", metric_logger)
    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}


@torch.no_grad()
def evaluate(data_loader, model, device):
    class_weights = torch.tensor([1.0, 1.0], dtype=torch.float32).cuda()
    criterion = torch.nn.CrossEntropyLoss(weight=class_weights)

    metric_logger = utils.MetricLogger(delimiter="  ")
    header = 'Test:'

    # switch to evaluation mode
    model.eval()

    all_preds = []
    all_targets = []

    for images, target in metric_logger.log_every(data_loader, 10, header):
        images = images.to(device, non_blocking=True)
        target = target.to(device, non_blocking=True)

        # compute output
        with torch.cuda.amp.autocast():
            output = model(images)
            loss = criterion(output, target)

        # ê²°ì • ìž„ê³„ê°’ ì ìš© ì—¬ë¶€ì— ë”°ë¥¸ ì˜ˆì¸¡ ë°©ì‹ ë¶„ê¸°
        threshold=0.5
        if threshold is not None and output.shape[1] == 2:
            # ì´ì§„ ë¶„ë¥˜ë¼ê³  ê°€ì •: ì†Œí”„íŠ¸ë§¥ìŠ¤ë¥¼ í†µí•´ í´ëž˜ìŠ¤ 1(positive)ì˜ í™•ë¥ ì„ ê³„ì‚°
            prob = torch.softmax(output, dim=1)[:, 1]
            preds = (prob > threshold).long()
        else:
            # ìž„ê³„ê°’ì´ ì§€ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë‹¤ì¤‘ í´ëž˜ìŠ¤ì¸ ê²½ìš°: argmaxë¡œ ì˜ˆì¸¡
            preds = torch.argmax(output, dim=1)

        # ì˜ˆì¸¡ê°’ ì €ìž¥
        # preds = torch.argmax(output, dim=1)
        all_preds.extend(preds.cpu().numpy())
        all_targets.extend(target.cpu().numpy())

        acc1 = accuracy(output, target, topk=(1,))[0]

        batch_size = images.shape[0]
        metric_logger.update(loss=loss.item())
        metric_logger.meters['acc1'].update(acc1.item(), n=batch_size)
        # metric_logger.meters['acc5'].update(acc5.item(), n=batch_size)

    # gather the stats from all processes
    metric_logger.synchronize_between_processes()
    print('* Acc@1 {top1.global_avg:.3f} loss {losses.global_avg:.3f}'
          .format(top1=metric_logger.acc1, losses=metric_logger.loss))

    print("\nConfusion Matrix:")
    cm = confusion_matrix(all_targets, all_preds)
    print(cm)

    print("\nClassification Report:")
    print(classification_report(all_targets, all_preds, digits=4))

    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}

"""
def inference(model, device):
    criterion = torch.nn.CrossEntropyLoss()

    metric_logger = utils.MetricLogger(delimiter="  ")
    header = 'Test:'

    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.CenterCrop((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.3882, 0.3882, 0.3882],
                                    std=[0.1461, 0.1461, 0.1461]),
        # transforms.Normalize(mean=[0.2444, 0.2444, 0.2444],
        #                             std=[0.1775, 0.1775, 0.1775]),


    ])

    csv_file = "/home/jovyan/ctm98/CNUH_data/test_inference.csv"
    dataset = InferenceDataset(csv_file, transform=transform)

    data_loader = DataLoader(dataset, batch_size=1, num_workers=0, pin_memory=True)

    model.eval()

    correct = 0
    total = 0
    final_outputs = []
    true_labels = []
    all_patch_outputs = []

    for images, targets in metric_logger.log_every(data_loader, 10, header):

        batch_size, num_patches, num_views, C, H, W = images.shape

        for batch_idx in range(batch_size):
            patch_final_outputs = []  # ðŸ”¹ í•œ ë°°ì¹˜ì—ì„œ ëª¨ë“  íŒ¨ì¹˜ì˜ ìµœì¢… output ì €ìž¥

            for patch_idx in range(num_patches):  # ðŸ”¹ Patch_0, Patch_1, Patch_2 ê°œë³„ ì²˜ë¦¬
                patch_outputs = []  # ðŸ”¹ ê° patchì— ëŒ€í•œ viewë³„ ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ ì €ìž¥

                for view_idx in range(num_views):  # ðŸ”¹ LCC & LMLO or RCC & RMLO
                    img_tensor = images[batch_idx, patch_idx, view_idx]  # (C, H, W)
                    img_tensor = img_tensor.to(device, non_blocking=True)

                    with torch.cuda.amp.autocast():
                        output = model(img_tensor.unsqueeze(0))  # (1, C, H, W)

                    prob = torch.softmax(output, dim=1)[:, 1].item()
                    pred = 1 if prob > 0.6 else 0
                    patch_outputs.append(pred)

                # ðŸ”¹ Patchë³„ ìµœì¢… output ê²°ì •
                if patch_outputs == [0, 0]:  
                    patch_final = 0
                else:  # [0,1], [1,0], [1,1] -> 1
                    patch_final = 1

                patch_final_outputs.append(patch_final)  # ðŸ”¹ íŒ¨ì¹˜ë³„ ìµœì¢… output ì €ìž¥

            all_patch_outputs.append(patch_final_outputs)  # ðŸ”¹ ë°°ì¹˜ë³„ patch outputs ì €ìž¥

            # ðŸ”¹ Votingì„ ì´ìš©í•œ ìµœì¢… ê²°ê³¼ ê²°ì •
            counter = Counter(patch_final_outputs)  # ðŸ”¹ ê°œìˆ˜ ì„¸ê¸°
            if counter[0] > counter[1] or counter[0] == counter[1]:  # 0ì´ ë” ë§Žìœ¼ë©´ 0
                final_decision = 0
            else:  # 1ì´ ë” ë§Žê±°ë‚˜ ë™ì ì´ë©´ 1
                final_decision = 1

            final_outputs.append(final_decision)  # ðŸ”¹ ë°°ì¹˜ë³„ ìµœì¢… ê²°ì • ì €ìž¥
            true_labels.append(targets[batch_idx].item())  # ðŸ”¹ ì‹¤ì œ ì •ë‹µ ì €ìž¥

            # ðŸ”¹ Accuracy ê³„ì‚°
            if final_decision == targets[batch_idx].item():  # ì˜ˆì¸¡ì´ ì •ë‹µê³¼ ì¼ì¹˜í•˜ë©´
                correct += 1
            total += 1

    # ðŸ”¹ ìµœì¢… ì¶œë ¥ ê²°ê³¼ (Patchë³„ Output, ì˜ˆì¸¡ê°’ & ì‹¤ì œ target ê°’ í•¨ê»˜ ì¶œë ¥)
    for batch_idx, (patch_outputs, final_output, target) in enumerate(zip(all_patch_outputs, final_outputs, true_labels)):
        print(f"\nâœ… Final Output for Batch {batch_idx}: {patch_outputs}")  # Patch 0,1,2ì˜ ê²°ê³¼ ì¶œë ¥
        print(f"âœ… Final Decision for Batch {batch_idx}: {final_output}")  # ìµœì¢… ê²°ì • ì¶œë ¥
        print(f"ðŸŽ¯ True Label (Target): {target}")  # ì‹¤ì œ ì •ë‹µ ì¶œë ¥

    # ðŸ”¹ Accuracy ì¶œë ¥
    accuracy = correct / total * 100
    print(f"\nâœ… Accuracy: {accuracy:.2f}%")

    # ðŸ”¹ Confusion Matrix ê³„ì‚°
    print("\nðŸ“Š Confusion Matrix:")
    cm = confusion_matrix(true_labels, final_outputs)
    print(cm)

    # ðŸ”¹ Classification Report ì¶œë ¥
    print("\nðŸ“Š Classification Report:")
    print(classification_report(true_labels, final_outputs, target_names=["Class 0", "Class 1"]))
"""

def inference(model, device):
    """
    Patch Ã— View êµ¬ì¡°ë¥¼ í™•ë¥  ê¸°ë°˜ìœ¼ë¡œ ê²°í•©í•˜ì—¬ ìµœì¢… ì˜ˆì¸¡ì„ ìˆ˜í–‰.
    - patch, viewë³„ë¡œ ì´ì§„ ì˜ˆì¸¡ ëŒ€ì‹  softmax í™•ë¥ ì„ ì¶”ì¶œ.
    - ë·°ë³„ í‰ê·  â†’ patchë³„ í™•ë¥ 
    - patchë³„ í™•ë¥ ì„ ë‹¤ì‹œ í‰ê· í•˜ì—¬ ìµœì¢… í™•ë¥ 
    """

    metric_logger = utils.MetricLogger(delimiter="  ")
    header = 'Test:'

    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        # transforms.CenterCrop((224, 224)),
        transforms.ToTensor(),
        # transforms.Normalize(mean=[0.3882, 0.3882, 0.3882], std=[0.1461, 0.1461, 0.1461]), # downstream
        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # imagenet
        transforms.Normalize(mean=[0.2492, 0.2492, 0.2492], std=[0.1920, 0.1920, 0.1920]) # pretrained
    ])

    csv_file = "F:/code/CNUH_data/test_inference.csv"
    dataset = InferenceDataset(csv_file, transform=transform)
    # ì›í•˜ëŠ” batch_size ì„¤ì • (ì˜ˆ: 4, 8, 16 ë“±)
    data_loader = DataLoader(dataset, batch_size=1, num_workers=0, pin_memory=True)

    model.eval()

    correct = 0
    total = 0
    final_outputs = []
    true_labels = []
    all_probs = []  # ROC/PR ê³„ì‚°ìš© í™•ë¥ 

    for images, targets in metric_logger.log_every(data_loader, 10, header):
        # images.shape = [batch_size, num_patches, num_views, C, H, W]
        batch_size, num_patches, num_views, C, H, W = images.shape

        for b_idx in range(batch_size):
            patch_probs_list = []  # patchë³„ í™•ë¥ (ë·° í‰ê· )

            for p_idx in range(num_patches):
                view_probs = []
                for v_idx in range(num_views):
                    img_tensor = images[b_idx, p_idx, v_idx].unsqueeze(0).to(device)
                    with torch.cuda.amp.autocast():
                        output = model(img_tensor)  # (1, num_classes)

                    # softmaxë¡œ ì–‘ì„± í´ëž˜ìŠ¤(1) í™•ë¥ 
                    prob = torch.softmax(output, dim=1)[:, 1].item()
                    view_probs.append(prob)

                # ë·°ë³„ í™•ë¥  í‰ê·  â†’ patch í™•ë¥ 
                patch_avg_prob = sum(view_probs) / len(view_probs)
                patch_probs_list.append(patch_avg_prob)

            # patch í™•ë¥ ë“¤ì„ ë‹¤ì‹œ í‰ê· (ë˜ëŠ” ë‹¤ë¥¸ ë°©ì‹) â†’ ìµœì¢… í™•ë¥ 
            # final_prob = sum(patch_probs_list) / len(patch_probs_list)
            # final_pred = 1 if final_prob > 0.5 else 0

            max_prob = max(patch_probs_list)
            final_pred = 1 if max_prob > 0.5 else 0

            final_outputs.append(final_pred)
            true_label = targets[b_idx].item()
            true_labels.append(true_label)
            all_probs.append(max_prob)

            if final_pred == true_label:
                correct += 1
            total += 1

    accuracy = correct / total * 100
    print(f"\nâœ… Accuracy: {accuracy:.2f}%")

    # Confusion Matrix
    from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score
    cm = confusion_matrix(true_labels, final_outputs)
    print("\nðŸ“Š Confusion Matrix:")
    print(cm)

    print("\nðŸ“Š Classification Report:")
    print(classification_report(true_labels, final_outputs, target_names=["Class 0", "Class 1"]))

    auroc = roc_auc_score(true_labels, all_probs)
    print(f"\nðŸ“Š AUROC: {auroc:.4f}")